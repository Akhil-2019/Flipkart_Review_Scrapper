{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyP21kGiN+SGo5UpOgi+5JI+",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "gpuClass": "standard"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Akhil-2019/Flipkart_Review_Scrapper/blob/main/Deep_Convolutional_Neural_Networks_in_Tensorflow_(MNIST).ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Implementing deep convolutional neural networks (CNNs) in Keras, and applying them to Image Analysis"
      ],
      "metadata": {
        "id": "CicMD7l8TJV1"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XCLbL9ONGYE4",
        "outputId": "49bd97dd-87a2-4163-9856-08705eacd4df"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive/; to attempt to forcibly remount, call drive.mount(\"/content/drive/\", force_remount=True).\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive/')"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from matplotlib import pyplot as plt\n",
        "import numpy as np\n",
        "%matplotlib inline"
      ],
      "metadata": {
        "id": "sSTfjL5SIJR2"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Dataset\n",
        "We will use the MNIST dataset. In this occassion the images won't be flattened prior to be used in the network, but they will be inputed as they are (images or arrays).\n",
        "\n",
        "Download the MNIST dataset from Keras:"
      ],
      "metadata": {
        "id": "iht5wG6QSBbY"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.datasets import mnist\n",
        "(X_train_img, y_train_img), (X_test_img, y_test_img) = mnist.load_data()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XYmJnYUMPqjD",
        "outputId": "e71be475-df1f-4516-9070-e785d4f5ac41"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/mnist.npz\n",
            "11490434/11490434 [==============================] - 0s 0us/step\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print('X_train_img dimensions: ', X_train_img.shape)\n",
        "print('y_train_img dimensions: ', y_train_img.shape)\n",
        "print('X_test_img dimensions: ', X_test_img.shape)\n",
        "print('y_test_img dimensions: ', y_test_img.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4f9Y8svJPxkq",
        "outputId": "ea9908fb-f1fa-4aa4-9085-f445c878e8c8"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "X_train_img dimensions:  (60000, 28, 28)\n",
            "y_train_img dimensions:  (60000,)\n",
            "X_test_img dimensions:  (10000, 28, 28)\n",
            "y_test_img dimensions:  (10000,)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "MNIST images are all pre-aligned (e.g. each image only contains a hand-drawn digit). In addition, the images all have the same square size of 28×28 pixels, and all are greyscale.\n",
        "\n",
        "CNN models (2D-CNNs, more precisely) takes 4D arrays as inputs: samples, 2D image coordinates, and channels. Colour RGB images have 3 channels (Red, Green and Blue), whilst greyscale images, 1 channel only. Therefore, we must reshape the data arrays to have a single channel:"
      ],
      "metadata": {
        "id": "MhHsOrYuQlEF"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "X_train = X_train_img.reshape((X_train_img.shape[0], 28, 28, 1))\n",
        "X_test = X_test_img.reshape((X_test_img.shape[0], 28, 28, 1))\n",
        "print('X_train dimensions: ', X_train.shape)\n",
        "print('X_test dimensions: ', X_test.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qs-IrlLgP4oB",
        "outputId": "9f6c5951-ee85-45ef-a0bd-62663b919386"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "X_train dimensions:  (60000, 28, 28, 1)\n",
            "X_test dimensions:  (10000, 28, 28, 1)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Classes in y_train and y_test are represented as unique integers:  0…9\n",
        " . We can, therefore, use a one hot encoding for the class element of each sample, transforming the integer into a 10 element binary vector with a 1 for the index of the class value, and 0 values for all other classes. We can achieve this with the to_categorical() utility function:"
      ],
      "metadata": {
        "id": "j7Jv_P19Rk0i"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.utils import to_categorical\n",
        "y_train = to_categorical(y_train_img)\n",
        "y_test = to_categorical(y_test_img)\n",
        "y_train[0:5,]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CaTiTH0VRAa8",
        "outputId": "657cf8a9-1599-4261-d055-269d2b01f92e"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[0., 0., 0., 0., 0., 1., 0., 0., 0., 0.],\n",
              "       [1., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
              "       [0., 0., 0., 0., 1., 0., 0., 0., 0., 0.],\n",
              "       [0., 1., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
              "       [0., 0., 0., 0., 0., 0., 0., 0., 0., 1.]], dtype=float32)"
            ]
          },
          "metadata": {},
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Now, we should proceed with the data normalisation. As we know pixel values should go from 0 to 255, sacaling the data requires dividing the arrays by 255. The data values are integers, therfore we must convert to reals first."
      ],
      "metadata": {
        "id": "XVl1im0rR94A"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "X_train = X_train.astype('float32')\n",
        "X_test = X_test.astype('float32')\n",
        "X_train /= 255\n",
        "X_test /= 255"
      ],
      "metadata": {
        "id": "q3ZTzJqnR9HH"
      },
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Building the Model"
      ],
      "metadata": {
        "id": "-S49y6i_TeWC"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras import Sequential\n",
        "from tensorflow.keras.layers import Dense\n",
        "from tensorflow.keras.layers import Conv2D\n",
        "from tensorflow.keras.layers import MaxPool2D\n",
        "from tensorflow.keras.layers import Flatten"
      ],
      "metadata": {
        "id": "U90BGUYhRqaS"
      },
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model1 = Sequential()\n",
        "model1.add(Conv2D(filters=32, kernel_size=(3,3), activation='relu', input_shape=(28,28,1)))\n",
        "model1.add(MaxPool2D((2,2)))\n",
        "model1.add(Flatten())\n",
        "model1.add(Dense(512, activation='relu'))\n",
        "model1.add(Dense(10, activation='softmax'))\n",
        "model1.summary()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "u2Q7r9rzTlGb",
        "outputId": "4cf99b75-544d-4f50-806f-04fc9a8f6b78"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " conv2d (Conv2D)             (None, 26, 26, 32)        320       \n",
            "                                                                 \n",
            " max_pooling2d (MaxPooling2D  (None, 13, 13, 32)       0         \n",
            " )                                                               \n",
            "                                                                 \n",
            " flatten (Flatten)           (None, 5408)              0         \n",
            "                                                                 \n",
            " dense (Dense)               (None, 512)               2769408   \n",
            "                                                                 \n",
            " dense_1 (Dense)             (None, 10)                5130      \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 2,774,858\n",
            "Trainable params: 2,774,858\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "Ej7wYMuBT5pp"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}